Agentic Developer Platform
This project implements a multi-agent, design-doc-first developer platform that automates software development tasks. It uses Google's Gemini LLM for intelligent planning and execution, orchestrated by LangGraph, within a secure Dockerized environment managed by OpenHands.

High-Level Architecture
The system is composed of two primary Docker services: an orchestrator that manages the agent workflow, and an openhands runtime that provides a sandboxed environment for file manipulation and command execution. The Coder and Planner agents within the orchestrator connect to the Gemini LLM to generate roadmaps and implementation plans.

graph TD
    subgraph "Development Environment (Local Machine)"
        A[User] -- Manages & Approves --> VSC[VS Code Dev Container]
        VSC -- Runs inside --> O[Orchestrator Container]
        O -- Executes --> GS[graph_skeleton.py]
    end

    subgraph "Docker Services (via docker-compose)"
        O -- Python Docker SDK --> D[Docker Socket]
        D -- Executes commands in --> OH[OpenHands Container]
        OH -- Mounts --> W[Workspace Volume]
    end
    
    subgraph "Agent Workflow (LangGraph in Orchestrator)"
        LG_Start[Start] --> DocAgent
        DocAgent --> Planner
        Planner -- design_doc --> Gemini[Google Gemini LLM]
        Gemini -- roadmap --> Planner
        Planner --> Architect
        Architect --> Coder
        Coder -- task --> Gemini
        Gemini -- implementation_plan --> Coder
        Coder -- run_shell --> OH
        OH -- output --> Coder
        Coder --> Tester
        Tester --> CICD
        CICD --> Loop{Continue?}
        Loop -- Yes --> Architect
        Loop -- No --> LG_End[End]
    end

    style VSC fill:#007ACC,color:#fff
    style Gemini fill:#4285F4,color:#fff
    style OH fill:#f6ae2d,color:#333

Prerequisites
Docker Desktop: Ensure the Docker engine is running.

VS Code: The recommended IDE for this project.

VS Code Dev Containers Extension: For a seamless, containerized development experience.

Google Gemini API Key: You can generate a free key from Google AI Studio.

Getting Started
1. Configure Your Environment
Clone the Repository: Download this project to your local machine.

Create the Environment File: Create a file named .env in the root of the project.

Add Your API Key: Add the following line to your .env file, replacing your_gemini_api_key_here with the key you generated from Google AI Studio.

GOOGLE_API_KEY="your_gemini_api_key_here"

Note: The .gitignore file is configured to prevent your .env file from ever being committed to the repository.

2. Launch the Development Environment
The easiest way to get started is to use the VS Code Dev Container.

Open the Project in VS Code: Open the main agentic-dev-platform folder in VS Code.

Reopen in Container: Wait for a pop-up in the bottom-right corner and click "Reopen in Container". This will build the Docker services and connect your VS Code instance directly into the orchestrator container.

3. Run the Agent Workflow
Once you are inside the Dev Container (the bottom-left corner of VS Code will be green), you can run the main agent script.

Open a Terminal: Use Terminal -> New Terminal in VS Code.

Execute the Script: Run the following command in the terminal:

python /workspaces/agentic-dev-platform/orchestrator/graph_skeleton.py

4. Review the Output
The script will execute the full multi-agent workflow. When it's complete, you can review the results:

Run Log: A high-level summary of the agents' actions will be written to run_log.txt.

Workspace: The implementation plans generated by the Coder agent will be saved as .md files in the workspace/ directory.

Agent Roles
DocAgent: Loads the docs/Design_Document.md to provide context for the other agents.

Planner: Uses the Gemini LLM to generate a project roadmap.

Architect: Selects the next available task from the roadmap.

Coder: Uses the Gemini LLM to create an implementation plan and executes verification commands.

Tester: Simulates running tests on the Coder's changes.

CICD: Simulates a build and deployment process for completed tasks.

LogAnalyst: Provides error analysis (triggered on failures).
